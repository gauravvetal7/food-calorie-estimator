{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f51ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import DenseNet121, DenseNet169, DenseNet201\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from tensorflow.keras.applications.densenet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ea6f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = '/kaggle/input/food-101/food-101/food-101/images/'\n",
    "train_meta_dir = '/kaggle/input/food-101/food-101/food-101/meta/train.txt'\n",
    "test_meta_dir = '/kaggle/input/food-101/food-101/food-101/meta/test.txt'\n",
    "\n",
    "def prepare_data(meta_dir, images_dir, dest_dir):\n",
    "    from collections import defaultdict\n",
    "    import os\n",
    "    from shutil import copy\n",
    "\n",
    "    classes_images_dict = defaultdict(list)\n",
    "    with open(meta_dir, 'r') as txt:\n",
    "        paths = [line.strip() for line in txt.readlines()]\n",
    "        for path in paths:\n",
    "            food = path.split('/')\n",
    "            classes_images_dict[food[0]].append(food[1] + '.jpg')\n",
    "\n",
    "    for food in classes_images_dict.keys():\n",
    "        food_dest_dir = os.path.join(dest_dir, food)\n",
    "        if not os.path.exists(food_dest_dir):\n",
    "            os.makedirs(food_dest_dir)\n",
    "        for img in classes_images_dict[food]:\n",
    "            src_path = os.path.join(images_dir, food, img)\n",
    "            img_dest_path = os.path.join(food_dest_dir, img)\n",
    "            if os.path.exists(src_path):\n",
    "                copy(src_path, img_dest_path)\n",
    "\n",
    "prepare_data(train_meta_dir, images_dir, 'train')\n",
    "prepare_data(test_meta_dir, images_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a61cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (224, 224)  \n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input, #densenet preprocessing\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "training_dir = 'train'\n",
    "validation_dir = 'test'\n",
    "batch_size = 32  \n",
    "num_classes = 101\n",
    "training_set_generator = train_datagen.flow_from_directory(\n",
    "    training_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_set_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "training_set = tf.data.Dataset.from_generator(\n",
    "    lambda: training_set_generator,\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=(\n",
    "        (None, image_size[0], image_size[1], 3),\n",
    "        (None, num_classes),\n",
    "    )\n",
    "    ).repeat().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "validation_set = tf.data.Dataset.from_generator(\n",
    "    lambda: validation_set_generator,\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=(\n",
    "        (None, image_size[0], image_size[1], 3),\n",
    "        (None, num_classes)\n",
    "    )\n",
    ").repeat().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "steps_per_epoch = len(training_set_generator)\n",
    "validation_steps = len(validation_set_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb9c5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(\n",
    "    f\"best_densenet_model.keras\", \n",
    "    monitor=\"val_accuracy\",\n",
    "    save_best_only=True,\n",
    "    mode=\"max\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=10,  \n",
    "    monitor='val_loss',\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d54f2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_densenet_model():\n",
    "    base_model = DenseNet201(\n",
    "        weights='imagenet', \n",
    "        include_top=False, \n",
    "        input_shape=(224, 224, 3)\n",
    "    )\n",
    "    \n",
    "    for layer in base_model.layers[:-50]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    inputs = base_model.input\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(512, activation='relu', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Dense(256, activation='relu', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    outputs = Dense(num_classes, activation='softmax', kernel_initializer='glorot_uniform')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_densenet_model()\n",
    "    \n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4), \n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb67bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    ax1.plot(history.history['accuracy'], label='Training accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation accuracy')\n",
    "    ax1.set_title('Model accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    ax2.plot(history.history['loss'], label='Training loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation loss')\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e116b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    training_set,\n",
    "    validation_data=validation_set,\n",
    "    epochs=50,  \n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[model_checkpoint, early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8854b02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_loss, final_accuracy = model.evaluate(\n",
    "    validation_set,\n",
    "    steps=validation_steps\n",
    ")\n",
    "print(f\"Validation loss: {final_loss:.4f}\")\n",
    "print(f\"Validation accuracy: {final_accuracy:.4f}\")\n",
    "\n",
    "model.save('final_densenet201_food101_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
